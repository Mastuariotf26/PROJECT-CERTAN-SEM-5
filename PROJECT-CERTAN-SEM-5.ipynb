{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "670cdd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "eps = np.finfo(float).eps\n",
    "from numpy import log2 as log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8734000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>mfr</th>\n",
       "      <th>type</th>\n",
       "      <th>calories</th>\n",
       "      <th>protein</th>\n",
       "      <th>fat</th>\n",
       "      <th>sodium</th>\n",
       "      <th>fiber</th>\n",
       "      <th>carbo</th>\n",
       "      <th>sugars</th>\n",
       "      <th>potass</th>\n",
       "      <th>vitamins</th>\n",
       "      <th>shelf</th>\n",
       "      <th>weight</th>\n",
       "      <th>cups</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100% Bran</td>\n",
       "      <td>N</td>\n",
       "      <td>C</td>\n",
       "      <td>70</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6</td>\n",
       "      <td>280</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>68.402973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100% Natural Bran</td>\n",
       "      <td>Q</td>\n",
       "      <td>C</td>\n",
       "      <td>120</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "      <td>135</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>33.983679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All-Bran</td>\n",
       "      <td>K</td>\n",
       "      <td>C</td>\n",
       "      <td>70</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>260</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>320</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>59.425505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>All-Bran with Extra Fiber</td>\n",
       "      <td>K</td>\n",
       "      <td>C</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>330</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>93.704912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Almond Delight</td>\n",
       "      <td>R</td>\n",
       "      <td>C</td>\n",
       "      <td>110</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>-1</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>34.384843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        name mfr type  calories  protein  fat  sodium  fiber  \\\n",
       "0                  100% Bran   N    C        70        4    1     130   10.0   \n",
       "1          100% Natural Bran   Q    C       120        3    5      15    2.0   \n",
       "2                   All-Bran   K    C        70        4    1     260    9.0   \n",
       "3  All-Bran with Extra Fiber   K    C        50        4    0     140   14.0   \n",
       "4             Almond Delight   R    C       110        2    2     200    1.0   \n",
       "\n",
       "   carbo  sugars  potass  vitamins  shelf  weight  cups     rating  \n",
       "0    5.0       6     280        25      3     1.0  0.33  68.402973  \n",
       "1    8.0       8     135         0      3     1.0  1.00  33.983679  \n",
       "2    7.0       5     320        25      3     1.0  0.33  59.425505  \n",
       "3    8.0       0     330        25      3     1.0  0.50  93.704912  \n",
       "4   14.0       8      -1        25      3     1.0  0.75  34.384843  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./cereal.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "705625ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy_node = 0 #initialize Entropy\n",
    "values = df.rating.unique() #Unique objects - 'Yes', 'No'\n",
    "for value in values:\n",
    "    fraction = df.rating.value_counts()[value]/len(df.rating)\n",
    "    entropy_node += -fraction*np.log2(fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da234a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.266786540694905"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(entropy_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d3a00d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute = 'name'\n",
    "target_variables = df.rating.unique() #This gives all 'Yes' and 'No'\n",
    "variables = df[attribute].unique() #This give diffrent features\n",
    "                                    #in that attribute (Like 'Sweet')\n",
    "entropy_attribute = 0\n",
    "for variable in variables:\n",
    "    entropy_each_feature = 0\n",
    "    for target_variable in target_variables:\n",
    "        num = len(df[attribute][df[attribute]==variable][df.rating ==target_variable]) #numerator\n",
    "        den = len(df[attribute][df[attribute]==variable]) #denominator\n",
    "        fraction = num/(den+eps) #pi\n",
    "        entropy_each_feature += -fraction*log(fraction+eps) #This calculates entropy for one feature Loke 'Sweet'\n",
    "    fraction2 = den/len(df)\n",
    "    entropy_attribute += -fraction*entropy_each_feature #Sums up all the entropy ETaste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6cd4a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(abs(entropy_attribute))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d389911f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_entropy(df):\n",
    "    Class = df.keys()[-1] #To make the code generic, changing target variable class name\n",
    "    entropy = 0\n",
    "    values = df[Class].unique()\n",
    "    for value in values:\n",
    "        fraction = df[Class].value_counts()[value]/len(df[Class])\n",
    "        entropy += -fraction*np.log2(fraction)\n",
    "    return entropy\n",
    "\n",
    "def find_entropy_attribue(df,attribute):\n",
    "    Class = df.keys()[-1]                 #To make the code generic, changing target variable class name\n",
    "    target_variables = df[Class].unique() #This gives all 'Yes' and 'No'\n",
    "    variables = df[attribute].unique()   #This gives different features\n",
    "    entropy2 = 0\n",
    "    for variable in variables:\n",
    "        entropy = 0\n",
    "        for target_variable in target_variables:\n",
    "            num = len(df[attribute][df[attribute]==variable][df[Class] ==target_variable])\n",
    "            den = len(df[attribute][df[attribute]==variable])\n",
    "            fraction = num/(den+eps)\n",
    "            entropy += -fraction*log(fraction+eps)\n",
    "        fraction2 = den/len(df)\n",
    "        entropy2 += -fraction2*entropy\n",
    "        return abs(entropy2)\n",
    "\n",
    "def find_winner(df):\n",
    "    Entropy_att = []\n",
    "    IG = []\n",
    "    for key in df.keys()[:-1]:\n",
    "        #Entropy_att.append(find_entropy_attrobite(df,key))\n",
    "        IG.append(find_entropy(df)-find_entropy_attribue(df,key))\n",
    "    return df.keys()[:-1][np.argmax(IG)]\n",
    "\n",
    "def get_subtable(df, node,value):\n",
    "    return df[df[node] ==value].reset_index(drop=True)\n",
    "\n",
    "def buildTree(df,tree=None):\n",
    "    Class = df.keys()[-1]    #To make the code generic, changing target\n",
    "                             #class name\n",
    "    \n",
    "    #Here we build our decision tree\n",
    "    \n",
    "    #Get attribute with maximum information gain\n",
    "    node = find_winner(df)\n",
    "    \n",
    "    #Get distinct value of that attribute e.g Slary is node and Low, Med\n",
    "    #and High are values\n",
    "    attValue = np.unique(df[node])\n",
    "    \n",
    "    #Create an empty dictionary to create tree\n",
    "    if tree is None:\n",
    "        tree={}\n",
    "        tree[node] = {}\n",
    "        \n",
    "    #We make Loop to construct a tree by calling this function recursively.\n",
    "    #in this we check if the subset is pure and stops if it is pure.\n",
    "    \n",
    "    for value in attValue:\n",
    "        subtable = get_subtable(df,node,value)\n",
    "        clValue,counts = np.unique(subtable['rating'],return_counts=True)\n",
    "        \n",
    "        if len(counts)==1: #checking purity of subset\n",
    "            tree[node][value] = clValue[0]\n",
    "        else:\n",
    "            tree[node][value] = buildTree(subtable) #calling the function recursively\n",
    "    return tree       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fe41ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = buildTree(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e368195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': {'100% Bran': 68.402973,\n",
      "          '100% Natural Bran': 33.983679,\n",
      "          'All-Bran': 59.425505,\n",
      "          'All-Bran with Extra Fiber': 93.704912,\n",
      "          'Almond Delight': 34.384843,\n",
      "          'Apple Cinnamon Cheerios': 29.509541,\n",
      "          'Apple Jacks': 33.174094,\n",
      "          'Basic 4': 37.038562,\n",
      "          'Bran Chex': 49.120253,\n",
      "          'Bran Flakes': 53.313813,\n",
      "          \"Cap'n'Crunch\": 18.042851,\n",
      "          'Cheerios': 50.764999,\n",
      "          'Cinnamon Toast Crunch': 19.823573,\n",
      "          'Clusters': 40.400208,\n",
      "          'Cocoa Puffs': 22.736446,\n",
      "          'Corn Chex': 41.445019,\n",
      "          'Corn Flakes': 45.863324,\n",
      "          'Corn Pops': 35.782791,\n",
      "          'Count Chocula': 22.396513,\n",
      "          \"Cracklin' Oat Bran\": 40.448772,\n",
      "          'Cream of Wheat (Quick)': 64.533816,\n",
      "          'Crispix': 46.895644,\n",
      "          'Crispy Wheat & Raisins': 36.176196,\n",
      "          'Double Chex': 44.330856,\n",
      "          'Froot Loops': 32.207582,\n",
      "          'Frosted Flakes': 31.435973,\n",
      "          'Frosted Mini-Wheats': 58.345141,\n",
      "          'Fruit & Fibre Dates; Walnuts; and Oats': 40.917047,\n",
      "          'Fruitful Bran': 41.015492,\n",
      "          'Fruity Pebbles': 28.025765,\n",
      "          'Golden Crisp': 35.252444,\n",
      "          'Golden Grahams': 23.804043,\n",
      "          'Grape Nuts Flakes': 52.076897,\n",
      "          'Grape-Nuts': 53.371007,\n",
      "          'Great Grains Pecan': 45.811716,\n",
      "          'Honey Graham Ohs': 21.871292,\n",
      "          'Honey Nut Cheerios': 31.072217,\n",
      "          'Honey-comb': 28.742414,\n",
      "          'Just Right Crunchy  Nuggets': 36.523683,\n",
      "          'Just Right Fruit & Nut': 36.471512,\n",
      "          'Kix': 39.241114,\n",
      "          'Life': 45.328074,\n",
      "          'Lucky Charms': 26.734515,\n",
      "          'Maypo': 54.850917,\n",
      "          'Muesli Raisins; Dates; & Almonds': 37.136863,\n",
      "          'Muesli Raisins; Peaches; & Pecans': 34.139765,\n",
      "          'Mueslix Crispy Blend': 30.313351,\n",
      "          'Multi-Grain Cheerios': 40.105965,\n",
      "          'Nut&Honey Crunch': 29.924285,\n",
      "          'Nutri-Grain Almond-Raisin': 40.69232,\n",
      "          'Nutri-grain Wheat': 59.642837,\n",
      "          'Oatmeal Raisin Crisp': 30.450843,\n",
      "          'Post Nat. Raisin Bran': 37.840594,\n",
      "          'Product 19': 41.50354,\n",
      "          'Puffed Rice': 60.756112,\n",
      "          'Puffed Wheat': 63.005645,\n",
      "          'Quaker Oat Squares': 49.511874,\n",
      "          'Quaker Oatmeal': 50.828392,\n",
      "          'Raisin Bran': 39.259197,\n",
      "          'Raisin Nut Bran': 39.7034,\n",
      "          'Raisin Squares': 55.333142,\n",
      "          'Rice Chex': 41.998933,\n",
      "          'Rice Krispies': 40.560159,\n",
      "          'Shredded Wheat': 68.235885,\n",
      "          \"Shredded Wheat 'n'Bran\": 74.472949,\n",
      "          'Shredded Wheat spoon size': 72.801787,\n",
      "          'Smacks': 31.230054,\n",
      "          'Special K': 53.131324,\n",
      "          'Strawberry Fruit Wheats': 59.363993,\n",
      "          'Total Corn Flakes': 38.839746,\n",
      "          'Total Raisin Bran': 28.592785,\n",
      "          'Total Whole Grain': 46.658844,\n",
      "          'Triples': 39.106174,\n",
      "          'Trix': 27.753301,\n",
      "          'Wheat Chex': 49.787445,\n",
      "          'Wheaties': 51.592193,\n",
      "          'Wheaties Honey Gold': 36.187559}}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15f93d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(inst,tree):\n",
    "    #This function is used to predict for any input variable\n",
    "    \n",
    "    #Recursively we go through the tree that we built earlier\n",
    "    \n",
    "    for nodes in tree.keys():\n",
    "        \n",
    "        value = inst[nodes]\n",
    "        tree = tree[nodes][value]\n",
    "        prediction = 0\n",
    "        \n",
    "        if type(tree) is dict:\n",
    "            prediction = predict(inst, tree)\n",
    "        else:\n",
    "            prediction = tree\n",
    "            break;\n",
    "            \n",
    "        return prediction\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f63d575",
   "metadata": {},
   "outputs": [],
   "source": [
    "inst = df.iloc[6] #this takes row tith index 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9179c5f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name        Apple Jacks\n",
       "mfr                   K\n",
       "type                  C\n",
       "calories            110\n",
       "protein               2\n",
       "fat                   0\n",
       "sodium              125\n",
       "fiber               1.0\n",
       "carbo              11.0\n",
       "sugars               14\n",
       "potass               30\n",
       "vitamins             25\n",
       "shelf                 2\n",
       "weight              1.0\n",
       "cups                1.0\n",
       "rating        33.174094\n",
       "Name: 6, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(inst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e1fcbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get prediction\n",
    "prediction = predict(inst, tree)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f154fcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'name' : '100% Bran','mfr' : 'N','calories' : '70','protein' : '4','fat' : '1','sodium' : '130','fiber' :  '10.0','carbo' : '5.0','sugars' : '6','potass' :  '280','vitamins': '25','shelf' : '3','weight' : '1.0','cups' : '0.33'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "159dd11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inst = pd.Series(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "97021041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Get prediction\n",
    "prediction = predict(inst, tree)\n",
    "display(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "643f1d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#Load data and store it into padnas DataFrame objects\n",
    "X = df.iloc[:, 0:13].values\n",
    "y = df.iloc[:, 13:14].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "eda1d25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                   y,\n",
    "                                                   test_size = 0.2,\n",
    "                                                   random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "46944dc9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Bran Flakes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [100]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DecisionTreeRegressor\n\u001b[0;32m      3\u001b[0m regr\u001b[38;5;241m=\u001b[39mDecisionTreeRegressor(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;66;03m#29\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mregr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m predictions \u001b[38;5;241m=\u001b[39mregr\u001b[38;5;241m.\u001b[39mpredict(x_test)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDecision Tree Testing score:\u001b[39m\u001b[38;5;124m\"\u001b[39m,regr\u001b[38;5;241m.\u001b[39mscore(x_test,y_test))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:1315\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\n\u001b[0;32m   1279\u001b[0m     \u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, X_idx_sorted\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1280\u001b[0m ):\n\u001b[0;32m   1281\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1282\u001b[0m \n\u001b[0;32m   1283\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1312\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1313\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1315\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1317\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1318\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_idx_sorted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_idx_sorted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1321\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:165\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    163\u001b[0m check_X_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(dtype\u001b[38;5;241m=\u001b[39mDTYPE, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    164\u001b[0m check_y_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 165\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_separately\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcheck_X_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_y_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n\u001b[0;32m    169\u001b[0m     X\u001b[38;5;241m.\u001b[39msort_indices()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:578\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validate_separately:\n\u001b[0;32m    573\u001b[0m     \u001b[38;5;66;03m# We need this because some estimators validate X and y\u001b[39;00m\n\u001b[0;32m    574\u001b[0m     \u001b[38;5;66;03m# separately, and in general, separately calling check_array()\u001b[39;00m\n\u001b[0;32m    575\u001b[0m     \u001b[38;5;66;03m# on X and y isn't equivalent to just calling check_X_y()\u001b[39;00m\n\u001b[0;32m    576\u001b[0m     \u001b[38;5;66;03m# :(\u001b[39;00m\n\u001b[0;32m    577\u001b[0m     check_X_params, check_y_params \u001b[38;5;241m=\u001b[39m validate_separately\n\u001b[1;32m--> 578\u001b[0m     X \u001b[38;5;241m=\u001b[39m check_array(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_X_params)\n\u001b[0;32m    579\u001b[0m     y \u001b[38;5;241m=\u001b[39m check_array(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    580\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:746\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    744\u001b[0m         array \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mastype(dtype, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsafe\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    745\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 746\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    749\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    750\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Bran Flakes'"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "regr=DecisionTreeRegressor(random_state=0)#29\n",
    "regr.fit(x_train,y_train)\n",
    "\n",
    "predictions =regr.predict(X_test)\n",
    "\n",
    "print(\"Decision Tree Testing score:\",regr.score(X_test,y_test))\n",
    "plt.scatter(y_test,predictions ,color='red')\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "dd03fe03",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This DecisionTreeRegressor instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [101]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m export_graphviz  \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# export the decision tree to a tree.dot file \u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# for visualizing the plot easily anywhere \u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[43mexport_graphviz\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtreelimited.dot\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m               \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmfr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcalories\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprotein\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msodium\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfiber\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcarbo\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msugars\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpotass\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvitamins\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mshelf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcups\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m                \u001b[49m\u001b[43mclass_names\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrating\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrounded\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproportion\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprecision\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilled\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m (graph,) \u001b[38;5;241m=\u001b[39m pydot\u001b[38;5;241m.\u001b[39mgraph_from_dot_file(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtreelimited.dot\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m Image(graph\u001b[38;5;241m.\u001b[39mcreate_png())\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_export.py:860\u001b[0m, in \u001b[0;36mexport_graphviz\u001b[1;34m(decision_tree, out_file, max_depth, feature_names, class_names, label, filled, leaves_parallel, impurity, node_ids, proportion, rotate, rounded, special_characters, precision, fontname)\u001b[0m\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexport_graphviz\u001b[39m(\n\u001b[0;32m    742\u001b[0m     decision_tree,\n\u001b[0;32m    743\u001b[0m     out_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    758\u001b[0m     fontname\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhelvetica\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    759\u001b[0m ):\n\u001b[0;32m    760\u001b[0m     \u001b[38;5;124;03m\"\"\"Export a decision tree in DOT format.\u001b[39;00m\n\u001b[0;32m    761\u001b[0m \n\u001b[0;32m    762\u001b[0m \u001b[38;5;124;03m    This function generates a GraphViz representation of the decision tree,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    857\u001b[0m \u001b[38;5;124;03m    'digraph Tree {...\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 860\u001b[0m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecision_tree\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    861\u001b[0m     own_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    862\u001b[0m     return_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1222\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1217\u001b[0m     fitted \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   1218\u001b[0m         v \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(estimator) \u001b[38;5;28;01mif\u001b[39;00m v\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m v\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1219\u001b[0m     ]\n\u001b[0;32m   1221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fitted:\n\u001b[1;32m-> 1222\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This DecisionTreeRegressor instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "from sklearn.tree import export_graphviz  \n",
    "  \n",
    "# export the decision tree to a tree.dot file \n",
    "# for visualizing the plot easily anywhere \n",
    "\n",
    "export_graphviz(regr, out_file ='treelimited.dot', \n",
    "               feature_names =['mfr','calories','protein','fat','sodium','fiber','carbo','sugars','potass','vitamins','shelf','weight','cups'],\n",
    "                class_names = 'rating',\n",
    "                rounded = True, proportion = False, precision = 2, filled = True)\n",
    "\n",
    "(graph,) = pydot.graph_from_dot_file('treelimited.dot')\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad94de5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
